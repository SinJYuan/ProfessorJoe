import os
import requests
import feedparser

NEWSAPI_KEY = os.getenv("NEWSAPI_KEY")

def fetch_newsapi():
    if not NEWSAPI_KEY:
        print("âŒ NEWSAPI_KEY not found.")
        return []

    news_url = f"https://newsapi.org/v2/top-headlines?category=business&language=en&pageSize=5&apiKey={NEWSAPI_KEY}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
        "Accept": "application/json",
        "Referer": "https://newsapi.org/",
        "Origin": "https://newsapi.org"
    }
    articles = []
    try:
        print("ğŸŒ æ­£åœ¨å‘ NewsAPI ç™¼é€è«‹æ±‚...")
        response = requests.get(news_url, headers=headers)
        print(f"ğŸ“¥ NewsAPI å›æ‡‰ç‹€æ…‹: {response.status_code}")
        response.raise_for_status()
        data = response.json()

        if data.get("status") != "ok":
            print("âŒ NewsAPI éŒ¯èª¤ç‹€æ…‹ï¼š", data)
            return []

        for article in data.get("articles", []):
            articles.append({
                "source": "NewsAPI",
                "title": article.get("title", ""),
                "url": article.get("url", "")
            })
        print(f"ğŸ“° NewsAPI æ“·å–åˆ° {len(articles)} å‰‡æ–°èã€‚")
        return articles

    except requests.exceptions.RequestException as e:
        print("âŒ NewsAPI è«‹æ±‚éŒ¯èª¤ï¼š", e)
        return []

def fetch_google_news():
    print("ğŸ“¡ æ“·å– Google News RSS")
    rss_url = "https://news.google.com/rss/search?q=business+stocks&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    articles = []
    try:
        feed = feedparser.parse(rss_url)
        for entry in feed.entries[:5]:
            articles.append({
                "source": "Google News",
                "title": entry.title,
                "url": entry.link
            })
        print(f"âœ… Google News æ“·å– {len(articles)} å‰‡æ–°èã€‚")
        return articles
    except Exception as e:
        print("âŒ Google News RSS æ“·å–éŒ¯èª¤:", e)
        return []

def fetch_yahoo_rss():
    print("ğŸ“¡ æ“·å– Yahoo è²¡ç¶“ RSS")
    rss_urls = [
        "https://tw.stock.yahoo.com/rss",             # å°è‚¡æ–°è
        "https://tw.stock.yahoo.com/rss/us-stock",    # ç¾è‚¡æ–°è
        "https://tw.stock.yahoo.com/rss/world",       # åœ‹éš›è²¡ç¶“
    ]

    all_articles = []
    for url in rss_urls:
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries[:3]:  # æ¯å€‹ä¾†æºæœ€å¤šå–3ç¯‡
                all_articles.append({
                    "source": "Yahoo Finance",
                    "title": entry.title,
                    "url": entry.link
                })
        except Exception as e:
            print(f"âŒ Yahoo RSS æ“·å–éŒ¯èª¤: {e}")

    print(f"âœ… Yahoo è²¡ç¶“å…±æ“·å– {len(all_articles)} å‰‡æ–°è")
    return all_articles

def aggregate_news_sources():
    news = []
    #news += fetch_newsapi()
    news += fetch_google_news()
    news += fetch_yahoo_rss()
    return news